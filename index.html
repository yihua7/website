<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-148984682-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-148984682-2');
  </script>
  
  <title>Yihua Huang</title>
  
  <meta name="author" content="Yihua Huang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr style="padding:0px">
            <td style="padding:2.5%;width:25%;max-width:25%">
              <a href="yihua.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="yihua.jpg" class="hoverZoomLink"></a>
            </td>
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Yihua Huang</name>
                </p>
                <p style="text-align:center">
                  <a href="mailto:huangyihua16@mails.ucas.ac.cn">Email</a> &nbsp/&nbsp
                  <a href="https://drive.google.com/file/d/1N4lD1FHbiebmtoVjKmKbcNF6hQXWLXw4/view?usp=sharing">CV</a>  &nbsp/&nbsp
                  <a href="https://www.linkedin.com/in/yihua-huang-0b2225245/">Linkedin</a>  &nbsp/&nbsp
                  <a href="https://github.com/yihua7/">Github</a>  &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?hl=en&user=zLil53UAAAAJ">Scholar</a>
                </p>

                <p>
                  I am a 1st year PhD student from <a href="https://xjqi.github.io/cvmi.html">CVMI Lab</a> supervised by <a href="https://xjqi.github.io/">Xiaojuan Qi</a>, focusing on 3D/4D reconstruction, interaction, simulation and editing. Previously, I completed my master degree at the <a href="http://english.ict.cas.cn/">Institute of Computing Technology</a>, <a href="https://english.cas.cn/">Chinese Academy of Sciences</a>, under the supervision of Professor <a href="http://geometrylearning.com/">Lin Gao</a>. I am grateful for the valuable guidance and assistance provided by Prof. Gao. Additionally, I have also worked closely with Doctor <a href="https://yanpei.me/">Yan-Pei Cao</a> and Professor <a href="https://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a>, both of whom have greatly contributed to my learning experience. Prior to that, I obtained my bachelor degree at the <a href="https://english.ucas.ac.cn/">University of Chinese Academy of Sciences</a>, where I was supervised by the respectful Prof. <a href="http://vipl.ict.ac.cn/people/xlchen/">Xilin Chen</a>, who introduced me to my research field and taught the foundational class on conducting research.
                  <!-- I'm very interested in 3D reconstruction from images, 3D shape analysis, and other 3D vision problems. My research interests also include robotics, slam and federated learning. -->
                </p>   
                <p style="color:magenta">
                <!-- <em>I will join <a href="https://xjqi.github.io/">Xiaojuan Qi</a> 's team as a Ph.D student , engaged in the research of 3D reconstruction and lifelong learning. </em> -->
                </p>
              </td>
            </tr>
          </tbody>
        </table>
    
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">          
          <tbody>
            <tr>
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                <heading>Research</heading>
              </td>
            </tr>
            
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [7]&nbsp&nbsp<papertitle>SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes</papertitle>
                  <br>
                  <a href="https://yihua7.github.io/website/"><strong>Yihua Huang</strong> </a><sup>*</sup>,
                  <a href="https://sunyangtian.github.io/">Yang-Tian Sun</a><sup>*</sup>,
                  <a href="https://github.com/ingra14m">Ziyi Yang</a><sup>*</sup>,
                  <a href="https://github.com/shawLyu">Xiaoyang Lyu</a><sup></sup>,
                  <a href="https://yanpei.me/">Yan-Pei Cao</a><sup>#</sup>,
                  <a href="https://xjqi.github.io/">Xiaojuan Qi</a><sup>#</sup>
                  <br>
                  <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024 &nbsp
                  <br>
                  <a href="https://arxiv.org/abs/2312.14937">paper</a> /
                  <a href="https://yihua7.github.io/SC-GS-web/">project page</a> /
                  <a href="https://github.com/yihua7/SC-GS">code</a> 
                  <br>
                  We introduce sparse-controlled gaussian splatting to synthesize dynamic novel views. With the learned node graph of sparse control points, real-time editing can be achieved with ARAP deformation by interactive dragging of users.
              </td>
            </tr>
            
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [6]&nbsp&nbsp<papertitle>NeRF-Texture: Synthesizing Neural Radiance Field Textures</papertitle>
                  <br>
                  <a href="https://yihua7.github.io/website/"><strong>Yihua Huang</strong></a>,
                  <a href="https://yanpei.me/">Yan-Pei Cao</a>,
                  <a href="https://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a>,
                  <a>Ying Shan</a>,
                  <a href="http://geometrylearning.com/">Lin Gao</a>
                  <br>
                  <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI), 2024</em> &nbsp
                  <br>
                  <!-- <a href="https://drive.google.com/file/d/1M8QTJPcDunY-WqSpFmWZ1xt9j3K6yKSg/view?usp=sharing">paper</a> / -->
                  <a href="https://yihua7.github.io/NeRF-Texture-web/">project page</a> /
                  <a href="https://github.com/yihua7/NeRF-Texture">code</a> 
                  <br>
                  An enhanced version of the SIGGRAPH version, incorporating a synthesis algorithm for arbitrary manifolds, featuring additional experiments, ablations, and comprehensive analysis.
              </td>
            </tr>
            
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [5]&nbsp&nbsp<papertitle>NeRF-Texture: Texture Synthesis with Neural Radiance Fields</papertitle>
                  <br>
                  <a href="https://yihua7.github.io/website/"><strong>Yihua Huang</strong></a>,
                  <a href="https://yanpei.me/">Yan-Pei Cao</a>,
                  <a href="https://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a>,
                  <a>Ying Shan</a>,
                  <a href="http://geometrylearning.com/">Lin Gao</a>
                  <br>
                  <em>ACM SIGGRAPH 2023 Conference Proceedings (SIGGRAPH), 2023</em> &nbsp
                  <br>
                  <a href="https://drive.google.com/file/d/1M8QTJPcDunY-WqSpFmWZ1xt9j3K6yKSg/view?usp=sharing">paper</a> /
                  <a href="https://yihua7.github.io/NeRF-Texture-web/">project page</a> /
                  <a href="https://github.com/yihua7/NeRF-Texture">code</a> 
                  <br>
                  We introduce a NeRF-based system to acquire, synthesize, map, and relight textures from real-world textures. A novel coarse-fine disentangling representation is proposed to model meso-structures of textures. Acquired textures are synthesized by an implicit patch-matching algorithm.
              </td>
            </tr>
            
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [4]&nbsp&nbsp<papertitle>Neural Radiance Fields from Sparse RGB-D Images for High-Quality View Synthesis</papertitle>
                  <br>
                  <a href="http://people.geometrylearning/yyj/">Yu-Jie Yuan</a>,
                  <a href="https://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a>,
                  <a href="https://yihua7.github.io/website/"><strong>Yihua Huang</strong></a>,
                  <a href="https://www.graphics.rwth-aachen.de/person/3/">Leif Kobbelt</a>,
                  <a href="http://geometrylearning.com/">Lin Gao</a>,
                  <br>
                  <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI)</em>, 2022 &nbsp
                  <br>
                  <a href="https://ieeexplore.ieee.org/document/9999509">paper</a> /
                  <a href="http://geometrylearning.com/rgbdnerf/">project page</a>
                  <!-- <a href="https://github.com/IGLICT/StylizedNeRF">code</a>  -->
                  <br>
                  We introduce a novel NeRF reconstruction method using RGB-D inputs from a consumer-level device (iPad), which enables high-quality reconstruction from sparse inputs. Experiments show that the proposed method achieves state-of-the-art novel view synthesis quality in this case of sparse RGB-D inputs.
              </td>
            </tr>
            
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [3]&nbsp&nbsp<papertitle>StylizedNeRF: Consistent 3D Scene Stylization as Stylized NeRF via 2D-3D Mutual Learning</papertitle>
                  <br>
                  <a href="https://yihua7.github.io/website/"><strong>Yihua Huang</strong></a>,
                  <a>Yue He</a>,
                  <a href="http://people.geometrylearning/yyj/">Yu-Jie Yuan</a>,
                  <a href="https://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a>,
                  <a href="http://geometrylearning.com/">Lin Gao</a>
                  <br>
                  <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022 &nbsp
                  <br>
                  <a href="https://arxiv.org/abs/2205.12183">arxiv</a> /
                  <a href="http://geometrylearning.com/StylizedNeRF/">project page</a> /
                  <a href="https://github.com/IGLICT/StylizedNeRF">code</a> 
                  <br>
                  We propose a novel mutual learning framework for 3D scene stylization that combines a 2D image stylization network and NeRF to fuse the stylization ability of 2D stylization network with the 3D consistency of NeRF.
              </td>
            </tr>
          
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                [2]&nbsp&nbsp<papertitle>Learning Critically: Selective Self Distillation in Federated Learning on Non-IID Data</papertitle>
                <br>
                <a href="https://yutinghe20.github.io/YutingHe/">Yuting He</a>,
                <a href="https://people.ucas.ac.cn/~yqchen">Yiqiang Chen</a>,
                <a>XiaoDong Yang</a>,
                <a>Hanchao Yu</a>,
                <a href="https://yihua7.github.io/website/"><strong>Yihua Huang</strong></a>,
                <a>Yang Gu</a>
                <br>
                <em>IEEE Transactions on Big Data (TBD)</em>, 2022 &nbsp
                <br>
                <a href="https://www.computer.org/csdl/journal/bd/5555/01/09826416/1EVdvuSiENO">paper</a>
                <br>
                We propose a Selective Self-Distillation method for Federated learning (FedSSD), which imposes adaptive constraints on the local updates by self-distilling the global model's knowledge and selectively weighting it by evaluating the credibility at both the class and sample level.
              </td>
            </tr>
          
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:10px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [1]&nbsp&nbsp<papertitle>Multiscale Mesh Deformation Component Analysis with Attention-based Autoencoders</papertitle>
                  <br>
                  <a href="http://people.geometrylearning.com/~jieyang/">Jie Yang</a>,
                  <a href="http://geometrylearning.com/">Lin Gao</a>,
                  <a href="https://qytan.com/">Qingyang Tan</a>,
                  <a href="https://yihua7.github.io/website/"><strong>Yihua Huang</strong></a>,
                  <a>Shihong Xia</a>
                  <a href="https://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a>
                  <br>
                  <em>IEEE Transactions on Visualization and Computer Graphics (TVCG)</em>, 2021 &nbsp
                  <br>
                  <a href="https://arxiv.org/abs/2012.02459">arxiv</a>
                  <br>
                  We propose a novel method to exact multiscale deformation components automatically with a stacked attention-based autoencoder.
              </td>
            </tr>

            <!-- <tr>
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                <heading>Services</heading>
              </td>
            </tr>
            <p>Paper reviewer: CVPR</p> -->

          </tbody>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td>
                <heading>Services</heading>
                <p>
                  <strong>Internships:</strong> Tencent (2023 Summer) <br>
                  <strong>Paper reviewer:</strong> CVPR, ICCV, ECCV, ACCV, Parcific Graphics, Virtual Reality, Computer & Graphics<br>
                  <strong>Talk speaker:</strong> Deep Blue College 2023, Graphics And Mixed Environment Seminar (GAMES) 2022<br>
                </p>
              </td>
            </tr>
          </tbody>
        </table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Kudos to <a href="https://jonbarron.info/">Dr. Jon Barron</a> for sharing his website template.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
